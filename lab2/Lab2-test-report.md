## Lab2 test report

### 1.实验二概述

使用从我们的课程中学到的网络编程知识,自己从头开始实现基于HTTP/1.1的HTTP服务器。另外,尝
试使用从类中学习的高并发编程技能来保证web服务器的性能。为测试HTTP服务器的性能,将测试运
行在不同的服务器机器环境中的服务器的性能差异、并发客户端数量不同时服务器的性能差异。

#### 1.1程序运行

本小组完成的是Advanced version 与 Basic version之间, 因为有代理部分和保持连接，但当对保持连接进行测试有错误，然后在写保持连接时没有使用epoll进行监听，是在循环等待下一次请求，影响了服务器性能，只有连续两个请求在短时间间隔内访问同一个socket时才会性能好(emmmm，非常好)。至于代理功能，我用了epoll监听了socket，然后对于数据转发采用了多线程处理，但最有对于单个请求能成功，一个客户时有少量错误请求，但当对于多个客户时会有少几个请求超时，并且对于连续测试(几千个请求多次测试，一次不会)之后可能服务器就没反映了(我猜测到可能是ab测试时最后没有主动断开，占用了资源，但也最后没改了)

如下图用一个端口作上游服务器，一个端口做代理服务器，然后对代理端口进行测试。(代码中添加了域名解析的功能，但测试百度的时候被拒绝访问了，所以就自己代码做上游服务器来测试了)

下图8886端口做代理，8888端口上游服务器测试cur GET

<div align="center"><img src="src/图2-1.png" alt="图2-1" title="图2-1" style="zoom:70%;" /></div>

<div align="center"><img src="src/图2-2.png" alt="图2-2" title="图2-2" style="zoom:70%;" /></div>

<div align="center"><img src="src/图2-3.png" alt="图2-3" title="图2-3" style="zoom:70%;" /></div>



#### 1.2 实验环境

linux内核版本:5.8.0-50-generic
cpu核数:8

cpu型号:Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz

#### 1.3代码版本

实验仅有1份代码,编程语言是c++,HTTP请求报文解析与响应使用了线程池技术, 可通过参数的调节而控制线程数量、服务器的ip地址和监听的端口号。

## 2.性能测试

本部分将分析比较在不同的服务器运行情况下HTTP服务器的性能差异、并发客户端的数量不同时HTTP
服务器的性能差异
性能指标:HTTP服务器每秒可以处理的HTTP请求数
测试工具:ab-Apache HTTP server benchmarking工具
测试结果:Time per request值

##### 测试1:不同的线程数目HTTP服务器的性能

ab测试工具将发送1000次访问,每次访问并发10个请求。通过指定number-thread值,可以测试不同的线程数环境下HTTP服务器的性能。

第一次测试不使用保持连接。(测试结果如下)

这里我测试的是时间，并且是服务器的处理每一请求的时间，其倒数 * 1000就是每s处理多少个请求

| 线程数 | Time per request(ms) | Requests per second |
| ------ | -------------------- | ------------------- |
| 1      | 8.604                | 116.23              |
| 2      | 4.226                | 236.62              |
| 4      | 2.221                | 450.29              |
| 8      | 1.205                | 829.55              |
| 12     | 0.969                | 1031.50             |
| 14     | 0.973                | 1027.94             |

这次测试很完美(我不敢相信，但确实是真实数据)，当线程数小于系统核数8时每个请求消耗的时间几乎是和线程数的线性增加呈现线性减少。但当其大于核数8之后就呈微小波动变化了。

第二次测试HTTP保持保持连接，除了请求时间之外还有一个参数请求错误的数量。

| 线程数 | Time per request(ms) | Failed requests: | Requests per second |
| ------ | -------------------- | ---------------- | ------------------- |
| 1      | 0.642                | 67               | 1557.29             |
| 2      | 0.294                | 49               | 3397.27             |
| 4      | 0.173                | 45               | 5770.31             |
| 8      | 0.029                | 36               | 34114.56            |
| 12     | 0.033                | 24               | 29924.89            |
| 14     | 0.049                | 28               | 20457.43            |

随着线程数增加请求时间的减少和不保持连接基本一致，但总体看，保持连接的时间要比不保持连接的请求时间少的多。对于请求错误，刚开始自己测的请求数小的时候比如10,20个请求时，用户数<线程数时就不会发生错误，但用户数>线程数时就会发生错误，之后测大量请求比如上图的1000个请求时都会发生错误，只是线程数较大时发生的错误较小，这时候我想到可能是两次请求之间请求报文没建立好，所以又改了下代码，在最后一次只剩下一部分报文没处理时将其连接到下一次请求报文中进行处理，但写完最后跑出来错误请求数更多，自闭，放弃了(emmmm，考研人要去复习高数了哈哈)

##### 测试2: 并发客户端数量不同时HTTP服务器的性能

ab测试工具将发送1000次访问,每次改变访问并发请求个数。通过指定并发用户数,可以测试不同的并发用户数环境下HTTP服务器的性能(测试时服务器开了8个线程以及不保持连接，1次1000个请求)

| 用户数 | Time per request (mean, across all concurrent requests) | Time per request:(mean) | Requests per second |
| ------ | ------------------------------------------------------- | ----------------------- | ------------------- |
| 1      | 8.928                                                   | 8.928                   | 112.00              |
| 2      | 4.496                                                   | 8.991                   | 222.44              |
| 4      | 2.321                                                   | 9.285                   | 430.79              |
| 8      | 1.149                                                   | 9.193                   | 870.22              |
| 12     | 1.140                                                   | 13.680                  | 877.21              |
| 16     | 1.141                                                   | 18.262                  | 876.12              |

如上图，当用户数小于线程数时，虽然从用户的角度看处理每个请求所消耗的时间没有减少，但从服务器方面看每秒处理的请求数呈线性增长，但当用户数大于线程数时，服务器每秒处理的请求数不在增加，而从用户角度看，每个请求所消耗的时间开始增加。